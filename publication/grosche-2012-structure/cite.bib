@inproceedings{grosche2012structure,
 abstract = {Content-based approaches to music retrieval are of great relevance as they do not require any kind of manually generated annotations. In this paper, we introduce the concept of structure fingerprints, which are compact descriptors of the musical structure of an audio recording. Given a recorded music performance, structure fingerprints facilitate the retrieval of other performances sharing the same underlying structure. Avoiding any explicit determination of musical structure, our fingerprints can be thought of as a probability density function derived from a self-similarity matrix. We show that the proposed fingerprints can be compared by using simple Euclidean distances without using any kind of complex warping operations required in previous approaches. Experiments on a collection of Chopin Mazurkas reveal that structure fingerprints facilitate robust and efficient content-based music retrieval. Furthermore, we give a musically informed discussion that also deepens the understanding of this popular Mazurka dataset.},
 address = {Porto, Portugal},
 author = {Grosche, Peter and Serrà, Joan and Müller, Meinard and Arcos, Josep Lluı́s},
 booktitle = {Proceedings of the 13th International Society for Music Information Retrieval Conference, ISMIR},
 doi = {10.5281/zenodo.1416170},
 pages = {55--60},
 title = {Structure-Based Audio Fingerprinting for Music Retrieval},
 url = {https://www.researchgate.net/publication/290561691},
 year = {2012}
}

